{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import penelope.notebook.dtm as vectorize_gui\n",
    "import penelope.notebook.dtm.load_DTM_gui as load_DTM_gui\n",
    "import penelope.notebook.word_trends as word_trends\n",
    "from bokeh.plotting import output_notebook\n",
    "from IPython.core.display import display\n",
    "from penelope.corpus import VectorizedCorpus\n",
    "\n",
    "import __paths__\n",
    "from notebooks.common.spacy_pipelines import spaCy_DTM_pipeline\n",
    "from notebooks.corpus_data_config import SSI, CorpusConfig\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    word_trend_data: word_trends.WordTrendData = None\n",
    "\n",
    "\n",
    "ssi: CorpusConfig = SSI(corpus_folder=__paths__.data_folder)\n",
    "state = State(word_trend_data=word_trends.WordTrendData())\n",
    "\n",
    "\n",
    "def corpus_loaded_callback(\n",
    "    corpus: VectorizedCorpus, corpus_tag: str, corpus_folder: str\n",
    "):  # pylint: disable=unused-argument\n",
    "    global state\n",
    "    print(\"Corpus succesfully vectorized!\")\n",
    "    print(\"Generating trend data!\")\n",
    "    state.word_trend_data.update(\n",
    "        corpus=corpus.group_by_year(),\n",
    "        corpus_folder=corpus_folder,\n",
    "        corpus_tag=corpus_tag,\n",
    "        n_count=1000,\n",
    "    )\n",
    "    print(\"Data successfully created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gui_vectorize = vectorize_gui.display_gui(\n",
    "    corpus_folder=__paths__.data_folder,\n",
    "    corpus_config=ssi,\n",
    "    pipeline_factory=spaCy_DTM_pipeline,\n",
    "    done_callback=corpus_loaded_callback,\n",
    ")\n",
    "\n",
    "display(gui_vectorize.layout(hide_input=False, hide_output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gui_load = load_DTM_gui.create_gui(\n",
    "    corpus_folder=__paths__.data_folder,\n",
    "    loaded_callback=corpus_loaded_callback,\n",
    ")\n",
    "\n",
    "display(gui_load.layout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gui_trends = word_trends.create_gui(\n",
    "    corpus=state.word_trend_data.corpus,\n",
    "    corpus_folder=state.word_trend_data.corpus_folder,\n",
    "    corpus_tag=state.word_trend_data.corpus_tag,\n",
    "    word_trend_data=state.word_trend_data,\n",
    ")\n",
    "display(gui_trends.layout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('text-analytics-symNAVlf-py3.8': venv)",
   "metadata": {
    "interpreter": {
     "hash": "f9f5370a66fe709225320b0a5e42eaf481fec3c92c4ac457a33063cd6d0e2297"
    }
   },
   "name": "Python 3.8.5 64-bit ('text-analytics-symNAVlf-py3.8': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
