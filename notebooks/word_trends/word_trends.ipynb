{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Word, or part-of-word, trend analysis\n",
    "\n",
    "### Text Processing Pipeline\n",
    "\n",
    "| | Building block | Arguments | Description |\n",
    "| -- | :------------- | :------------- | :------------- |\n",
    "| âš™ | <b>SetTagger</b>SpacyModel | 'en' | spaCy as PoS tagger\n",
    "| ðŸ“œ| <b>LoadText</b> | reader_opts, transform_opts | Text stream provider\n",
    "| ðŸ”Ž | <b>Tqdm</b> | âšª | Progress indicator\n",
    "| âŒ› | <b>Passthrough</b> | âšª | Passthrough\n",
    "| ðŸ”¨ | Spacy<b>ToTagged</b>Frame | âšª | PoS tagging\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename | Checkpoint (tagged frames) to file\n",
    "| ðŸ”¨ | TaggedFrame<b>ToTokens</b> | extract_tagged_tokens_opts, filter_opts | Tokens extractor\n",
    "| ðŸ”¨ | <b>TokensTransform</b> | tokens_transform_opts | Tokens transformer\n",
    "| ðŸ”¨ | <b>ToDocumentContentTuple</b> | âšª | Protocol/API adapter\n",
    "| ðŸ”Ž | <b>Tqdm</b> | âšª | Progress indicator\n",
    "| ðŸ”¨ | <b>ToDTM</b> | vectorize_opts| DTM vectorizer\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename| Checkpoint (DTM) to file\n",
    "\n",
    "### User instructions\n",
    "\n",
    "#### Compute DTM\n",
    "\n",
    "This notebook implements the entire processing pipeline from plain text to computed (and stored)\n",
    "document-term matrix that are the basis for the word trend exploration.\n",
    "\n",
    "For large corpora the DTM processing time can be considerable and in such a case you\n",
    "should consider using the CLI-version of the processing pipeline.\n",
    "\n",
    "Note that the computed DTM is saved on disk in the specified folder. You must enter a\n",
    "tag that will be used when namin the (principel) result data file. This file will be named\n",
    "tag + `_vectorized_data.pickle` and uniquely identifies the bundle of files that makes\n",
    "up the result. Note that if the `tag` already exists in specified folder then it will will\n",
    "be overwritten. The tag can be used to describe the main compute arguments. If the\n",
    "The result files will be stored in a subfolder named with the tag if the `Create folder` option is checked.\n",
    "\n",
    "| | Config element |  Description |\n",
    "| -- | :------------- | :------------- |\n",
    "| | Corpus type | Type of corpus, disabled since only text corpora are allowed in this notebook.\n",
    "| | Source corpus file | Select file (ZIP) or folder that contains the text documents.\n",
    "| | Output tag | String that will be prefix to result files. Only valid filename chars allowed.\n",
    "| | Output folder | Target folder for result files.\n",
    "| | Part-of-speech groups | Groups of tags to include in DTM given corpus PoS-schema\n",
    "| | Remove stopwords | Remove common stopwords using NLTK language specific stopwords\n",
    "| | Extra stopwords | Additional stopwords\n",
    "| | Filename fields | Specifies attribute values to be extracted from filenames\n",
    "\n",
    "N.B. Note that PoS schema (e.g. SUC, Universal, ON5 Penn Treebank tag sets) and language must be set for each corpus.\n",
    "\n",
    "#### Load DTM\n",
    "\n",
    "<b>To select a corpus:</b> <b>1)</b> press <b>`Change`</b> to open the file browser, <b>2)</b> find and select the file you want to open and <b>3)</b> press <b>`Change`</b> again to confirm the file and close the prowser. Then you can load the corpus by pressing <b>`Load`</b>.\n",
    "\n",
    "#### Word trends\n",
    "\n",
    "Add words of interest and/or regular expressions in the text box. The system will automatically plot matching word - words not plotted does not exist in the (processed) corpus. The regular expressions must be surrounded by vertical bars `|`. To find words ending with `tion` you can enter `|.*tion$|` in the textbox. I might seem cryptical, but is a very powerful notation for searching words. The vertical bars is specified only so that the system can distinguish the regexp from \"normal\" words. The actual expression is `^.*tion$`. The dot and star`.*` matches any character (the dot) any number of times (the `*`). The dollar sign `$` indicates the word ending. So this expression matches all words that begins with any number of characters follwoed, by the character sequence `tion` at the end of the word. To match all words starting with `info`you can enter `|^info.*|` where `^` specifies the start of the word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bokeh.plotting import output_notebook\n",
    "from IPython.core.display import display\n",
    "\n",
    "import __paths__  # pylint: disable=unused-import\n",
    "from notebooks.word_trends import word_trends_gui\n",
    "\n",
    "output_notebook()\n",
    "display(word_trends_gui.create_gui(corpus_folder=__paths__.data_folder, corpus_config_name=\"SSI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
