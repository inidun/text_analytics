{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Text Analysis\n",
    "\n",
    "### Vectorize the corpus to a BoW corpus <!-- (text_analytic_tools.corpus.vectorized_corpus.VectorizedCorpus) -->\n",
    "\n",
    "Use the script `scripts/vectorize_protocols.py` to create a BoW corpus.\n",
    "\n",
    "```bash\n",
    "    python scripts/vectorize_corpus.py \\    \n",
    "        --to-lower \\\n",
    "        --no-remove-accents \\\n",
    "        --min-length 2 \\\n",
    "        --keep-numerals \\\n",
    "        --no-keep-symbols \\\n",
    "        --only-alphanumeric \\\n",
    "        --file-pattern '*.txt' \\\n",
    "        --meta-field \"document_type:_:0\" \\    \n",
    "        --meta-field \"document_id:_:2\" \\\n",
    "        --meta-field \"year:_:3\" \\\n",
    "        ./data/legal_instrument_corpus.txt.zip \\\n",
    "        ./data \\\n",
    "```\n",
    "\n",
    "<!--\n",
    "The script calls `generate_corpus` in `text_analytic_tools.corpus.corpus_vectorizer`:\n",
    "-->\n",
    "\n",
    "The resulting corpus are stored in the specified output folder in two files; a numpy file containing the DTM and a Python pickled file with the dictionary and a document index.\n",
    "\n",
    "<!--\n",
    "### Prepare text files for Sparv\n",
    "\n",
    "The Sparv pipeline requires that the individual document are stored as (individual) XML files. The shell script `sparvit-to-xml` can be used to add a root tag to all text files in a Zip archive. The resulting XML files iare stored as a new Zip archive.\n",
    "\n",
    "```bash\n",
    " sparvit-to-xml --input riksdagens_protokoll_content_corpus.zip --output riksdagens_protokoll_content_corpus_xml.zip\n",
    " ```\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import bokeh.plotting\n",
    "import types\n",
    "\n",
    "assert sys.version_info > (3,8,5)\n",
    "\n",
    "root_folder = os.path.join(os.getcwd().split('text_analytics')[0], 'text_analytics')\n",
    "corpus_folder = os.path.join(root_folder, 'data')\n",
    "\n",
    "sys.path = sys.path + [ root_folder, globals()['_dh'][-1] ]\n",
    "\n",
    "bokeh.plotting.output_notebook(hide_banner=True)\n",
    "\n",
    "container = types.SimpleNamespace(corpus=None, handle=None, data_source=None, data=None, figure=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously vectorized corpus\n",
    "<!--\n",
    "The corpus was created with the following settings:\n",
    " - Tokens were converted to lower case.\n",
    " - Only tokens that contains at least one alphanumeric character (isalnum).\n",
    " - Accents are ot removed (deacc)\n",
    " - Min token length 2 (min_len)\n",
    " - Max length not set (max_len)\n",
    " - Numerals are removed (numerals, -N)\n",
    " - Symbols are removed (symbols, -S)\n",
    "\n",
    "Use the `vectorize_corpus` script to create a new corpus with different settings.\n",
    "\n",
    "The corpus is processed in the following ways when loaded:\n",
    "\n",
    " - Exclude tokens having a total word count less than `Min count`\n",
    " - Include at most `Top count` most frequent words.\n",
    " - Group and sum up documents by year.\n",
    " - Normalize token distribution over years to 1.0\n",
    " \n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "end_execution_time": "2020-08-31T18:34:55.995Z",
     "start_execution_time": "2020-08-31T18:34:55.854Z"
    }
   },
   "outputs": [],
   "source": [
    "import word_trends_corpus_gui as corpus_gui\n",
    "ui = corpus_gui.display_gui(corpus_folder, container=container)"
   ]
  },
  {
   "source": [
    "## Display word trends"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word_trends_gui\n",
    "word_trends_gui.display_gui(container)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('text_analytics': pipenv)",
   "language": "python",
   "name": "python_defaultSpec_1600176618938"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}