{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import glove\n",
    "from penelope.corpus.readers import TextTokenizer\n",
    "\n",
    "root_folder = (lambda x: os.path.join(os.getcwd().split(x)[0], x))(\"text_analytics\")\n",
    "sys.path.insert(0, root_folder)\n",
    "\n",
    "\n",
    "corpus_folder = os.path.join(root_folder, \"data\")\n",
    "corpus_path = os.path.join(corpus_folder, \"legal_instrument_corpus_preprocessed.zip\")\n",
    "\n",
    "tokenizer = TextTokenizer(\n",
    "    source=corpus_path,\n",
    "    filename_pattern=\"*.txt\",\n",
    "    fix_whitespaces=True,\n",
    "    fix_hyphenation=True,\n",
    "    filename_fields=None,\n",
    ")\n",
    "\n",
    "reader = (tokens for _, tokens in tokenizer)\n",
    "\n",
    "corpus = glove.Corpus()\n",
    "\n",
    "corpus.fit(reader, 5, False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('text_analytics': venv)",
   "metadata": {
    "interpreter": {
     "hash": "feaa6644a67d98bc2c380c25a7ae5b1ab301b95bfc0add23663419f9cdbe38f8"
    }
   },
   "name": "Python 3.8.2 64-bit ('text_analytics': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
