{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This notebook implements a processing pipeline from computes word co-occurrences from plain text. The term-term co-occurrence matrix is transformed into a DTM corpus that has a vocabulary consisting of token-pairs. The co-occurring word trends can hence be xxplored using the ordinary word trends analysis tools.\n",
    "\n",
    "For large corpora the processing time can be considerable and in such a case you\n",
    "should consider using the CLI-version of the processing pipeline.\n",
    "\n",
    "### Text Processing Pipeline\n",
    "\n",
    "| | Building block | Arguments | Description |\n",
    "| -- | :------------- | :------------- | :------------- |\n",
    "| âš™ | <b>SetTagger</b>SpacyModel | 'en' | spaCy as PoS tagger\n",
    "| ðŸ“œ| <b>LoadText</b> | reader_opts, transform_opts | Text stream provider\n",
    "| ðŸ”Ž | <b>Tqdm</b> | âšª | Progress indicator\n",
    "| âŒ› | <b>Passthrough</b> | âšª | Passthrough\n",
    "| ðŸ”¨ | Spacy<b>ToTaggedFrame</b> | spaCy tagger | PoS tagging\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename | Checkpoint (tagged frames) to file\n",
    "| ðŸ”¨ | TaggedFrame<b>ToTokens</b> | extract_tagged_tokens_opts, filter_opts | Tokens extractor\n",
    "| ðŸ”¨ | <b>TokensTransform</b> | tokens_transform_opts | Tokens transformer\n",
    "| ðŸ”¨ | <b>Vocabulary</b> | âšª | Generate a token to integer ID mappin\n",
    "| ðŸ”¨ | <b>ToDocumentContentTuple</b> | âšª | Protocol/API adapter\n",
    "| ðŸ”¨ | <i>Partition</i> | âšª | Partition corpus into subsets based on predicate (year)\n",
    "| ðŸ”Ž | <b>ToCoOccurrence</b> | âšª | Transform each partition to TTM matrices\n",
    "| ðŸ”¨ | <i>ToCooFrame</i> | âšª| Transform TTM into data frame with normalized values\n",
    "| ðŸ’¾ | <i>Checkpoint</i> | checkpoint_filename| Store co-occurrence data frame\n",
    "| ðŸ”¨ | <b>ToDTM</b> | vectorize_opts| Transform data frame into DTM\n",
    "| ðŸ’¾ | <b>Checkpoint</b> | checkpoint_filename| Checkpoint (DTM) to file\n",
    "\n",
    "\n",
    "### How the co-occurrence counts are computed\n",
    "\n",
    "The co-occurrences are computed using a sliding window of size (D + 1 + D) that word by word moves through each document in the corpus, and keeps count of how many windows each pair of words co-occur in. Note that all windows will (currenty) always have an odd number of words, and the reason for this is the conditioned co-occurrence described below.\n",
    "\n",
    "The computation is done by first creating a (streamed) windowed corpus, consisting of all windows. From this corpus a DTM (document-term-matrix) is created, giving counts for each word in each window. This DTM is then used to compute a TTM (term-term-matrix) simply by multiplying the DTM with a transposed version of itself.\n",
    "\n",
    "Please note that the process of generating windows (currently) ignores sentences, paragraphs etc.\n",
    "\n",
    "### Concept co-occurence\n",
    "\n",
    "The algorithm also allows for computing a conditioned co-occurrence, where the set of windows are constrained so that the center-most word must one of a number of specified (concept) words. This results in a set of co-occurrences that occur in close proximity (i.e. the max distance of D) of the center-most word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bokeh.plotting import output_notebook\n",
    "from IPython.core.display import display\n",
    "\n",
    "import __paths__  # pylint: disable=unused-import\n",
    "from notebooks.co_occurrence import co_occurrence_gui\n",
    "\n",
    "output_notebook()\n",
    "display(co_occurrence_gui.create_gui(corpus_config_name=\"SSI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
